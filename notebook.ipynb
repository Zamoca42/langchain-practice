{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 ~ 3.2 \n",
    "\n",
    "- LLMs and Chat Models\n",
    "- Predict Messsages\n",
    "- Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between France and Germany varies depending on the specific locations being compared. However, the approximate driving distance between Paris, France and Berlin, Germany is around 1,050 kilometers (650 miles) when traveling via the most direct route."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The distance between France and Germany varies depending on the specific locations being compared. However, the approximate driving distance between Paris, France and Berlin, Germany is around 1,050 kilometers (650 miles) when traveling via the most direct route.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# StreamingStdOutCallbackHandler은 문자가 생성될 때 마다 출력을 해주는 콜백 핸들러.\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}?\")\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "prompt = template.format(country_a=\"France\", country_b=\"Germany\")\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = llm.predict(\"How many planets are in the solar system?\")\n",
    "b = chat.predict(\"How many planets are in the solar system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 8 planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "  SystemMessage(\n",
    "      content=\"You are a geography expert. And you only reply in Italian.\",\n",
    "    ),\n",
    "  AIMessage(content=\"Ciao, mi chiamo Paolo\"),\n",
    "  HumanMessage(content=\"What is the distance between Mexico and the Thailand?\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Template\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}?\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(language=\"Greek\", name=\"Socrates\", country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트 템플릿 작성 후 format에서 placeholder에 값을 넣지 않으면 에러 발생\n",
    "\n",
    "```python\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}?\")\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "template.format()\n",
    "```\n",
    "\n",
    "![스크린샷 2024-03-23 오후 7 54 14](https://github.com/Zamoca42/langchain-practice/assets/96982072/f551daff-fe48-4e35-9d73-2abb16d819b8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 \n",
    "\n",
    "- OutputParser and LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Parser는 텍스트로만 응답하는 LLM의 응답형태를 변경\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello,how, are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='수성, 금성, 지구, 화성, 목성, 토성, 천왕성, 해왕성'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['수성', '금성', '지구', '화성', '목성', '토성', '천왕성', '해왕성']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max {max_items} in korean. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the planets\")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "print(result)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['피카츄', '파이리', '꼬부기', '이상해씨', '리자드왕.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 생성 prompt | model | output_parser\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\"max_items\": 5, \"question\": \"What are the pokemons?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n",
    "- Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "chef_template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_template | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a vegetarian version of Spaghetti Aglio e Olio, you can easily replace the Parmesan cheese with a vegetarian alternative such as nutritional yeast or a plant-based Parmesan-style cheese. These alternatives provide a similar savory and cheesy flavor to the dish without using animal products.\n",
      "\n",
      "To prepare a plant-based Parmesan-style cheese, you can make a simple mixture using the following ingredients:\n",
      "\n",
      "Ingredients:\n",
      "- 1/2 cup raw cashews\n",
      "- 2 tablespoons nutritional yeast\n",
      "- 1/2 teaspoon garlic powder\n",
      "- 1/2 teaspoon salt\n",
      "\n",
      "Instructions:\n",
      "1. In a food processor or blender, combine the raw cashews, nutritional yeast, garlic powder, and salt.\n",
      "2. Pulse the mixture until it reaches a fine, crumbly texture similar to grated Parmesan cheese.\n",
      "3. Taste and adjust the seasoning if needed.\n",
      "\n",
      "You can sprinkle this plant-based Parmesan cheese alternative on top of your Spaghetti Aglio e Olio just like you would with traditional Parmesan cheese. It adds a delicious nutty and cheesy flavor to the dish while keeping it vegetarian-friendly. Enjoy your meal!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='For a vegetarian version of Spaghetti Aglio e Olio, you can easily replace the Parmesan cheese with a vegetarian alternative such as nutritional yeast or a plant-based Parmesan-style cheese. These alternatives provide a similar savory and cheesy flavor to the dish without using animal products.\\n\\nTo prepare a plant-based Parmesan-style cheese, you can make a simple mixture using the following ingredients:\\n\\nIngredients:\\n- 1/2 cup raw cashews\\n- 2 tablespoons nutritional yeast\\n- 1/2 teaspoon garlic powder\\n- 1/2 teaspoon salt\\n\\nInstructions:\\n1. In a food processor or blender, combine the raw cashews, nutritional yeast, garlic powder, and salt.\\n2. Pulse the mixture until it reaches a fine, crumbly texture similar to grated Parmesan cheese.\\n3. Taste and adjust the seasoning if needed.\\n\\nYou can sprinkle this plant-based Parmesan cheese alternative on top of your Spaghetti Aglio e Olio just like you would with traditional Parmesan cheese. It adds a delicious nutty and cheesy flavor to the dish while keeping it vegetarian-friendly. Enjoy your meal!')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"), \n",
    "    (\"human\", \"{recipe}\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "  \"cuisine\": \"Italian\", \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 ~ 3.2 \n",
    "\n",
    "1. LLMs and Chat Models\n",
    "2. Predict Messsages\n",
    "3. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between France and Germany varies depending on the specific locations being considered. However, the approximate driving distance between Paris, France and Berlin, Germany is around 1,050 kilometers (650 miles).'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}?\")\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "prompt = template.format(country_a=\"France\", country_b=\"Germany\")\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = llm.predict(\"How many planets are in the solar system?\")\n",
    "b = chat.predict(\"How many planets are in the solar system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 8 planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "  SystemMessage(\n",
    "      content=\"You are a geography expert. And you only reply in Italian.\",\n",
    "    ),\n",
    "  AIMessage(content=\"Ciao, mi chiamo Paolo\"),\n",
    "  HumanMessage(content=\"What is the distance between Mexico and the Thailand?\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Template\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}?\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(language=\"Greek\", name=\"Socrates\", country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트 템플릿 작성 후 format에서 placeholder에 값을 넣지 않으면 에러 발생\n",
    "\n",
    "```python\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}?\")\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "template.format()\n",
    "```\n",
    "\n",
    "![스크린샷 2024-03-23 오후 7 54 14](https://github.com/Zamoca42/langchain-practice/assets/96982072/f551daff-fe48-4e35-9d73-2abb16d819b8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 \n",
    "\n",
    "1. OutputParser and LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Parser는 텍스트로만 응답하는 LLM의 응답형태를 변경\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello,how, are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='수성, 금성, 지구, 화성, 목성, 토성, 천왕성, 해왕성'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['수성', '금성', '지구', '화성', '목성', '토성', '천왕성', '해왕성']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a list generating machine. Everything you ar asked will be answered with a comma seperated list of max {max_items} in korean. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the planets\")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "print(result)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['피카츄', '파이리', '꼬부기', '이상해씨', '리자드왕.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 생성 prompt | model | output_parser\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\"max_items\": 5, \"question\": \"What are the pokemons?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
